{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import string, unicodedata\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from contraction import fix\n",
    "import inflect\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sunilchawla\\\\Desktop\\\\ass2\\\\code'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data_df/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path+\"pos_neg.csv\",sep = \",\")\n",
    "df_test = pd.read_csv(path+\"pos_neg_test.csv\",sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "df_test.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>This film lacked something I couldn't put my f...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002</td>\n",
       "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003</td>\n",
       "      <td>When I was little my parents took me along to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieID                                             review  rate  label\n",
       "0        0  Story of a man who has unnatural feelings for ...     3      0\n",
       "1    10000  Airport '77 starts as a brand new luxury 747 p...     4      0\n",
       "2    10001  This film lacked something I couldn't put my f...     4      0\n",
       "3    10002  Sorry everyone,,, I know this is supposed to b...     1      0\n",
       "4    10003  When I was little my parents took me along to ...     1      0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieID</th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieID                                             review  rate  label\n",
       "0        0  Once again Mr. Costner has dragged out a movie...     2      0\n",
       "1    10000  This is an example of why the majority of acti...     4      0\n",
       "2    10001  First of all I hate those moronic rappers, who...     1      0\n",
       "3    10002  Not even the Beatles could write songs everyon...     3      0\n",
       "4    10003  Brass pictures (movies is not a fitting word f...     3      0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['review']=df_train['review'].str.lower()\n",
    "df_test['review'] =df_test['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_contractions(text):\n",
    "    \"\"\"Replace contractions in string of text\"\"\"\n",
    "    return fix(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['review'] = df_train['review'].apply(lambda x: \" \".join(replace_contractions(x) for x in x.split()))\n",
    "df_test['review'] = df_test['review'].apply(lambda x: \" \".join(replace_contractions(x) for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = strip_html(text)\n",
    "    text = denoise_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train['review'] = df_train['review'].apply(lambda x: normalize(x))\n",
    "df_test['review'] = df_test['review'].apply(lambda x: normalize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        story of a man who has unnatural feelings for ...\n",
       "1        airport '77 starts as a brand new luxury 747 p...\n",
       "2        this film lacked something i could not put my ...\n",
       "3        sorry everyone,,, i know this is supposed to b...\n",
       "4        when i was little my parents took me along to ...\n",
       "5        \"it appears that many critics find the idea of...\n",
       "6        the second attempt by a new york intellectual ...\n",
       "7        i do not know who to blame, the timid writers ...\n",
       "8        this film is mediocre at best. angie harmon is...\n",
       "9        the film is bad. there is no other way to say ...\n",
       "10       this film is one giant pant load. paul schrade...\n",
       "11       the plot for descent, if it actually can be ca...\n",
       "12       plot is not worth discussion even if it hints ...\n",
       "13       this film is about a male escort getting invol...\n",
       "14       this movie must be in line for the most boring...\n",
       "15       a worn-out plot of a man who takes the rap for...\n",
       "16       i saw this movie at a drive-in in 1959. until ...\n",
       "17       ghost of dragstrip hollow is a typical 1950's ...\n",
       "18       \"ghost of dragstrip hollow\" was one of the man...\n",
       "19       \"ghost of dragstrip hollow\" appears to take pl...\n",
       "20       the characters are unlikeable and the script i...\n",
       "21       kareena kapoor in a bikini hmmmmmmmm.akshay ku...\n",
       "22       i rented this on dvd and i kind of feel bad si...\n",
       "23       vijay krishna acharya's 'tashan' is a over-hyp...\n",
       "24       the worst movie i have seen since tera jadoo c...\n",
       "25       summer season is here when the choices in the ...\n",
       "26       shame on yash raj films and aditya chopra who ...\n",
       "27       first lesson that some film makers (particular...\n",
       "28       if this is a 2008 product from one of the bigg...\n",
       "29       i had some expectation for the movie, since it...\n",
       "                               ...                        \n",
       "24970    its not as good as the first movie,but its a g...\n",
       "24971    sure, it was cheesy and nonsensical and at tim...\n",
       "24972    spoilers through: i really am in the minority ...\n",
       "24973    i have to say, i loved vanishing point. i've s...\n",
       "24974    to start off with, since this movie is a remak...\n",
       "24975    i have to agree with most of the other posts. ...\n",
       "24976    any movie that shows federal pigs (persons in ...\n",
       "24977    in canadian director kari skogland's film adap...\n",
       "24978    i saw this movie last night after waiting ages...\n",
       "24979    this movie is about basically human relations,...\n",
       "24980    i was surprised at just how much i enjoyed thi...\n",
       "24981    i saw this film in winnipeg recently - appropr...\n",
       "24982    as perhaps one of the few canadians who did no...\n",
       "24983    i was very moved by the story and because i am...\n",
       "24984    what i loved about the on-screen adaptation of...\n",
       "24985    i had a chance to see a screening of this movi...\n",
       "24986    this is a really interesting movie. it is an a...\n",
       "24987    i saw the movie recently and really liked it. ...\n",
       "24988    i thought this movie was hysterical. i have wa...\n",
       "24989    ...this is a classic with so many great dialog...\n",
       "24990    the most hillarious and funny brooks movie i e...\n",
       "24991    \"life stinks\" is a parody of life and death, h...\n",
       "24992    this is the kind of film you want to see with ...\n",
       "24993    i have not read the other comments on the film...\n",
       "24994    life stinks (1991) was a step below mel brooks...\n",
       "24995    seeing as the vote average was pretty low, and...\n",
       "24996    the plot had some wretched, unbelievable twist...\n",
       "24997    i am amazed at how this movie(and most others ...\n",
       "24998    a christmas together actually came before my t...\n",
       "24999    working-class romantic drama from director mar...\n",
       "Name: review, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['review']= df_train['review'].str.replace('[^\\w\\s]','')\n",
    "df_test['review']= df_test['review'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = [\"above\", \"such\", \"each\", \"same\", \"once\", \"only\", \"might\", \"between\", \"until\", \"against\", \"below\", \"up\", \"down\", \"over\", \"all\", \"few\", \"most\", \"no\", \"not\", \"too\", \"very\", \"won\", \"again\", \"nor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "customStopWords=[]\n",
    "for x in stopwords.words('english'):\n",
    "     if x not in stop_word:\n",
    "            customStopWords.append(x)\n",
    "customStopWords = set(customStopWords+list(punctuation)+['hmm','hmmm','hmmmm','hmmmmm','hmmmmmm','hmmmmmmm','hmmmmmmmm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'about',\n",
       " 'after',\n",
       " 'ain',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'during',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hmm',\n",
       " 'hmmm',\n",
       " 'hmmmm',\n",
       " 'hmmmmm',\n",
       " 'hmmmmmm',\n",
       " 'hmmmmmmm',\n",
       " 'hmmmmmmmm',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'under',\n",
       " 've',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customStopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['review'] = df_train['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in customStopWords))\n",
    "df_test['review'] = df_test['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in customStopWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'appears many critics find idea woody allen drama unpalatable good reason unbearably wooden pretentious imitations bergman let us not kid critics mostly supportive allens bergman pretensions allens whining accusations contrary notwithstanding not get allen generally applauded originality imitating bergman contemporaneous brian depalma excoriated ripping hitchcock suspensehorror films robin woods view strange form cultural snobbery would agree'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['review'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews] \n",
    "    return reviews\n",
    "\n",
    "df_train['review'] = pd.Series(preprocess_reviews(df_train['review']))\n",
    "df_test['review'] = pd.Series(preprocess_reviews(df_test['review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loneavenger               1\n",
       "rememberor                1\n",
       "spinthebottle             1\n",
       "kraftebing                1\n",
       "tragedyit                 1\n",
       "disappointmentby          1\n",
       "competentlydelivered      1\n",
       "sleepwalkersscreenplay    1\n",
       "villans                   1\n",
       "3000i                     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rare_word = pd.Series(' '.join(df_train['review']).split()).value_counts()[-10:]\n",
    "train_rare_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usamy                1\n",
       "realz                1\n",
       "scarcity             1\n",
       "stageor              1\n",
       "unequivocalhighly    1\n",
       "cattrallwho          1\n",
       "craftsmanlike        1\n",
       "onefighting          1\n",
       "straightgay          1\n",
       "asis                 1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rare_word = pd.Series(' '.join(df_test['review']).split()).value_counts()[-10:]\n",
    "test_rare_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rare_word = list(train_rare_word.index)\n",
    "df_train['review'] = df_train['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in train_rare_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rare_word = list(test_rare_word.index)\n",
    "df_test['review'] = df_test['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in test_rare_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()\n",
    "def lemmatize_word(text):\n",
    "    word_sent = word_tokenize(text)\n",
    "    text = [lmtzr.lemmatize(word) for word in word_sent]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['words'] = df_train['review'].apply(lambda x: lemmatize_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['words'] = df_test['review'].apply(lambda x: lemmatize_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['words_sent'] = [\" \".join(list_sent) for list_sent in df_train['words'].values]\n",
    "df_test['words_sent'] = [\" \".join(list_sent) for list_sent in df_test['words'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        story man unnatural feeling pig start opening ...\n",
       "1        airport 77 start brand new luxury 747 plane lo...\n",
       "2        film lacked something could not put finger fir...\n",
       "3        sorry everyone know supposed art film wow hand...\n",
       "4        little parent took along theater see interior ...\n",
       "5        appears many critic find idea woody allen dram...\n",
       "6        second attempt new york intellectual le 10 yea...\n",
       "7        not know blame timid writer clueless director ...\n",
       "8        film mediocre best angie harmon funny bag hamm...\n",
       "9        film bad no way say story weak outdated especi...\n",
       "10       film one giant pant load paul schrader utterly...\n",
       "11       plot descent actually called plot two notewort...\n",
       "12       plot not worth discussion even hint corruption...\n",
       "13       film male escort getting involved murder inves...\n",
       "14       movie must line most boring movie year not eve...\n",
       "15       wornout plot man take rap woman murder case eq...\n",
       "16       saw movie drivein 1959 until howard duck consi...\n",
       "17       ghost dragstrip hollow typical 1950s teen turm...\n",
       "18       ghost dragstrip hollow one many 50 movie hotro...\n",
       "19       ghost dragstrip hollow appears take place spot...\n",
       "20       character unlikeable script awful waste talent...\n",
       "21       kareena kapoor bikini hmmmmmmmmakshay kumarani...\n",
       "22       rented dvd kind feel bad since dawson lugacy e...\n",
       "23       vijay krishna acharyas tashan overhyped styliz...\n",
       "24       worst movie seen since tera jadoo chal gaya no...\n",
       "25       summer season choice cinema limited hottest mo...\n",
       "26       shame yash raj film aditya chopra seems lost i...\n",
       "27       first lesson film maker particularly inspired ...\n",
       "28       2008 product one biggest production house indi...\n",
       "29       expectation movie since nice star cast return ...\n",
       "                               ...                        \n",
       "24970    not good first moviebut good solid movie good ...\n",
       "24971    sure cheesy nonsensical time corny least filmm...\n",
       "24972    spoiler really minority one liked movie not cl...\n",
       "24973    say loved vanishing point ive seen original pr...\n",
       "24974    start since movie remake classic rating lowere...\n",
       "24975    agree most post comedy drama leaned little muc...\n",
       "24976    movie show federal pig person government power...\n",
       "24977    canadian director kari skoglands film adaptati...\n",
       "24978    saw movie last night waiting age age released ...\n",
       "24979    movie basically human relation interaction bet...\n",
       "24980    surprised much enjoyed most thoughtfully deliv...\n",
       "24981    saw film winnipeg recently appropriate given l...\n",
       "24982    perhaps one few canadian not read book high sc...\n",
       "24983    very moved story going something similar paren...\n",
       "24984    loved onscreen adaptation stone angel stayed t...\n",
       "24985    chance see screening movie recently believe th...\n",
       "24986    really interesting movie action movie comedy m...\n",
       "24987    saw movie recently really liked surprised crie...\n",
       "24988    thought movie hysterical watched many time rec...\n",
       "24989    classic many great dialog scene nobody miss ni...\n",
       "24990    most hillarious funny brook movie ever seen wa...\n",
       "24991    life stink parody life death happiness depress...\n",
       "24992    kind film want see glass wine fire foot up not...\n",
       "24993    not read comment film judging average rating s...\n",
       "24994    life stink 1991 step below mel brook productio...\n",
       "24995    seeing vote average pretty low fact clerk vide...\n",
       "24996    plot wretched unbelievable twist however chemi...\n",
       "24997    amazed movieand most others average 5 star low...\n",
       "24998    christmas together actually came time ive rais...\n",
       "24999    workingclass romantic drama director martin ri...\n",
       "Name: words_sent, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['words_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = df_train['label']\n",
    "Y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3),max_df=0.9,min_df=2)\n",
    "train_document = vectorizer.fit_transform(df_train['words_sent'])\n",
    "test_document = vectorizer.transform(df_test['words_sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score using _tfidf: 1.00\n",
      "Test set score using _tfidf: 0.89392\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C=22,penalty='l2')\n",
    "classifier = clf.fit(train_document, Y_train)\n",
    "print(\"Training set score using _tfidf: {:.2f}\" .format(classifier.score(train_document, Y_train)))\n",
    "print(\"Test set score using _tfidf: {:.5f}\".format(classifier.score(test_document, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ['er','drf']\n",
    "r = ['drff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['er', 'drf'], dtype='<U3')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
